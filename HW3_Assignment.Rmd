---
title: "STAT 385 Fall 2019 - Homework Assignment 03"
date: "Due by 12:00 PM 10/13/2019"
author: "Xinhe Xu"
output: html_document
---


## The Homework Problems
```{r}
library(tidyverse)
```

Below you will find problems for you to complete as an individual. It is fine to discuss the homework problems with classmates, but cheating is prohibited and will be harshly penalized if detected.

### 1. Create a custom volume measurement function that will convert the following units of volume:

a. 13 imperial (liquid) cups to cubic inches.
```{r}
transa = function(input) {
  input * 14.4375
} 
transa(13)
```

b. 2.5 US customary (liquid) gallons to fluid ounces.
```{r}
transb = function(input) {
  input * 128
}
transb(2.5)
```

c. 3 US customary (dry) teaspoons to milliliters.
```{r}
transc = function(input) {
  input * 4.92892159
}
transc(3)
```

d. 75 (dry) liters to imperial quarts.
```{r}
transd = function(input) {
  input * 0.87987663
}
transd(75)
```

### 2. Do the following:

a. create a 25 $\times$ 25 matrix with autoregressive structure with $p = 9/10$, every element in the matrix should be equal to $(9/10)^{|i-j|}$ where `i` is the row index and `j` is the column index.  Report the row and column sums of this matrix.
```{r}
n = rep(0,25)
p = 9/10
newmatrix = matrix(n, nrow = 25, ncol = 25, byrow = TRUE)
for (i in 1:25) {
  for (j in 1:25) {
    newmatrix[i,j] = p ^ abs(i-j)
  }
}
x = colSums(newmatrix)
y = rowSums(newmatrix)
x
y
```

b. run the commands:

```{r, eval=FALSE}
set.seed(13)
x <- c(10, 10) 
n <- 2

x = c(x, rnorm(1, mean = 0, sd = 2))
while((sd(x) / sqrt(length(x))) >= 0.1 | length(x) <3 ) {
  x = c(x, rnorm(1, mean = 0, sd = 2))
}
length(x)
```

Create a while loop which concatenates a new mean-zero normal random variables that have $\sigma = 2$ to the existing vector `x` at every iteration.  Have this loop terminate when the standard error (estimated standard deviation of `x` divided by $\sqrt{n}$) is lower than 1/10.  Report $n$.  

c. repeat part **b** and report $n$ after running the commands:    

```{r, eval=FALSE}
set.seed(13)
x <- rnorm(0, sd = 2)
n <- 1

x = c(x, rnorm(1, mean = 0, sd = 2))
while((sd(x) / sqrt(length(x))) >= 0.1 | length(x) <3 ) {
  x = c(x, rnorm(1, mean = 0, sd = 2))
}
length(x)

```

d. The sample size required to get a standard error lower than 1/10 was smaller in part **c** than it was in part **b**.  We would expect for this to be the case before we ran any code.  Why?
```{r}
#since at the beigining, the standard deviation of part c is larger than part b so if we want to get the standard error lower than 1/10, so in part b we need more sample size to lower the standard error than part c.
```


### 3. Do the following (Efron's bootstrap):

a. load in the dataset [dataHW3.csv](https://uofi.box.com/shared/static/mwntzgp2rvyewf292k6i62pykjz1onnw.csv)
```{r}
getdata = read.csv("https://uofi.box.com/shared/static/mwntzgp2rvyewf292k6i62pykjz1onnw.csv")
getdata 
```

b. call the first column of this dataset x. Compute the statistic `(mean(x) - 10)/se(x)` where `se` is shorthand for standard error (see the previous problem for the definition of standard error).  
```{r}
x = getdata[, 1]
a = (mean(x) - 10)/(sd(x)/sqrt(length(x)))
a 
```

c. now resample the elements of x with replacement 10000 times, and compute and store the statistic (mean(x') - mean(x))/se(x') at each iteration where x' corresponds to the resample of the elements of x. Call the vector which contains these reasampled statistics `resamples'.  Use an apply function for this part.  
```{r}
resamples = rep(0, 1e4)
new1 = function(i) {
  y = sample(x, replace = TRUE)
  i = (mean(y) - mean(x)) / (sd(y) / sqrt(length(y)))
  result1 = c()
  result1 = append(result1, i)
  return (result1)
}

new2 = function(i2, l) {
  result2 = sapply(1:l, new1)
  return (result2)
}

resamples = new2(x, 1e4)

```

d.  run the command `hist(resamples, breaks = 20)' to make a histogram, include this histogram in your assignment.
```{r}
hist(resamples, breaks = 20)
```

e. repeat parts **b** through **d** with respect to the second column of dataHW3.csv.  Would you say that the test statistic calculated from each column has the same distribution?
```{r}
x = getdata[, 2]
b = (mean(x) - 10)/(sd(x)/sqrt(length(x)))

resamples = rep(0, 1e4)
new1 = function(i) {
  y = sample(x, replace = TRUE)
  i = (mean(y) - mean(x)) / (sd(y) / sqrt(length(y)))
  result1 = c()
  result1 = append(result1, i)
  return (result1)
}

new2 = function(i2, l) {
  result2 = sapply(1:l, new1)
  return (result2)
}

resamples = new2(x, 1e4)
hist(resamples, breaks = 20)
```


### 4. Do the following:

a. make sure you have the dataset [WPP2010.csv](/Users/mac/Desktop/stat385/xinhexu2/WPP2010.csv) (your file location may need to change) and then run the commands: 

```{r, eval = FALSE}
# load in UN dataset and remove irrelevant variables
#don't show the worning
options(warn=-1)
#read wpp2010 data
WPP2010 <- read.csv("/Users/mac/Desktop/stat385/xinhexu2/WPP2010.csv", header = TRUE)
# change the name of wpp2010's third column to "region"
colnames(WPP2010)[3] <- c("region")
# change the name of wpp2010's sixth column to "year"
colnames(WPP2010)[6] <- c("year")
#change the name of the column from 7th to 17th of the age 0 to age 50
colnames(WPP2010)[7:17] <- paste("age", 0:10 * 5, sep = "")
#select specific data
WPP2010 <- WPP2010[, c(3, 6, 11, 12)]

# restrict attention to countries of interest
countries <- c("Canada", "Mexico", "United States of America")

# obtain population data for all countries for all years
dataset <- WPP2010[WPP2010[, 1] %in% countries, ]
# change factor data in third column to numeric data
dataset[, 3] <- as.numeric(levels(dataset[, 3]))[dataset[, 3]]
#change factor data in fourth column to numeric data
dataset[, 4] <- as.numeric(levels(dataset[, 4]))[dataset[, 4]]
#let the value in third column and fourth divide 1000
dataset[, 3:4] <- dataset[, 3:4] / 1000

# get population dataset for this analysis corresponding to the 
# Census years 
dataset.years <- dataset[dataset[, 2] %in% 
  c("1960", "1970", "1980", "1990", "2000", "2010"), ]
#change the year of second colum to factor data
dataset.years[, 2] <- factor(dataset.years[, 2])
# split the data according to the year
dataset.years.list <- split(dataset.years, f = as.factor(dataset.years[, 2]))
#sum the population of the age from 20 to 25 and 25 to 30 each year.
pops <- unlist(lapply(dataset.years.list, function(x) sum(x[, 3:4])))

#c
getdata = as.numeric(levels(dataset[,2]))[dataset[,2]]
sum1 = sum(subset(dataset, getdata <=1970)[,3:4])
amount = sum(dataset[,3:4])
result = sum1 / amount
result
```

b. The code in part **a** is partially commented.  Add comments to all remaining lines of code to make the script clear.

c. Determine the proportion of mainland North American males aged 20-29 that lived in 1970 or before.



### 5. With the tidyverse package and its functions, do the following with the [CCSO Bookings Data](https://uofi.box.com/shared/static/9elozjsg99bgcb7gb546wlfr3r2gc9b7.csv):
```{r}
ccso = read.csv("https://uofi.box.com/shared/static/9elozjsg99bgcb7gb546wlfr3r2gc9b7.csv")
ccso$BOOKING.DATE = as.Date(ccso$BOOKING.DATE, format = "%m/%d/%Y")
```

a. show only the 2012 bookings for people ages 17-23 years old not residing in Illinois and show the data dimension
```{r}
one = filter(ccso, Age.at.Arrest <= 23 & Age.at.Arrest >= 17 & BOOKING.DATE > as.Date("2011-12-31") & BOOKING.DATE < as.Date("2013-01-01") & STATE != "ILLINOIS")
dim(one)

```

b. show only the bookings for people who have employment status as "student" booked after the year 2012 residing in Danville and show the data dimension
```{r}
two = filter(ccso,BOOKING.DATE >= as.Date("2013-01-01") & EMPLOYMENT.STATUS =="Student" & CITY == "DANVILLE")
dim(two)
```

c. show only the bookings for Asian people residing in the cities of Champaign or Urbana and show the data dimension
```{r}
three = filter(ccso, RACE == "Asian/Pacific Islander" & (CITY == "CHAMPAIGN" | CITY == "URBANA"))
dim(three)
```

d. repeat parts a-c using only pipe operators
```{r}
#a
ccso %>% filter(Age.at.Arrest <= 23 & Age.at.Arrest >= 17 & BOOKING.DATE > as.Date("2011-12-31") & BOOKING.DATE < as.Date("2013-01-01") & STATE != "ILLINOIS")%>% dim()
#b
ccso %>% filter(BOOKING.DATE >= as.Date("2013-01-01") & EMPLOYMENT.STATUS =="Student" & CITY == "DANVILLE")%>% dim()
#c
ccso %>% filter(RACE == "Asian/Pacific Islander" & (CITY == "CHAMPAIGN" | CITY == "URBANA"))%>% dim()
```


## Select in-class tasks

Completion of select in-class tasks will be worth 1 point and will be graded largely by completion. Obvious errors and incomplete work will recieve deductions. Problems 3-5 are directly copied from your notes. Problems 1-2 are copied from the notes with minor alterations. In these problems I ask that you display the first 5 rows of the dataset instead of the entire dataset.

1. Load in the CCSO dataset, discover 3 factor (or categorical) variables and 3 numeric variables. Show the first 5 rows of this dataset with only those 6 variables. 
```{r}
inccso = read.csv("https://uofi.box.com/shared/static/9elozjsg99bgcb7gb546wlfr3r2gc9b7.csv")
choose = select(ccso, STATE, JACKET.NUMBER, EMPLOYMENT.STATUS, Age.at.Arrest, Age.at.Release)
head(choose, n = 5)
```

2. Rename one of the factor variables to a name that is either easier to understand than the original variable name. Show the first 5 rows of the dataset with all variables such that the variable with the new name is the first column in the dataset.
```{r}
getCCSO = ccso %>% select(EMPLOYMENT.STATUS, everything())
new_CCSO = rename(getCCSO, Location = STATE)
head(new_CCSO, n = 5)
```

3. Write 3 separate loops: a for loop, while loop, and repeat loop that give the same result. The result should be the cumulative sum of Days in jail among Black people whose Arrest Ages 18-24 with Student as Employment status within the CCSO Bookings Data.
```{r}
#for loop
newgetOne = filter(ccso, RACE == "Black" & EMPLOYMENT.STATUS =="Employed - Full Time" & Age.at.Arrest <= 26 & ccso$Age.at.Arrest >= 15)
temp = dim(newgetOne)[1]
for (i in 1:temp) {
  a = a + as.numeric(newgetOne[i,]$Days.in.Jail)
}
a

```
```{r}
#while loop
n = 1
result = 0
while(n <= temp){
  result = result + as.numeric(newgetOne[n,]$Days.in.Jail)
  n = n + 1
}
result
```

4. Here are some images of R code. Read the code, debug it if necessary, and judge it on its efficiency and correctness. Decide on which set of code is better and improve the better one.

a.

![](https://uofi.box.com/shared/static/2x1h70d5skqpxwke8ftw7xx1rwu41397.jpg)
```{r}
```

b.

![](https://uofi.box.com/shared/static/xn2lop472prp18720uevoj4dpyfmtxwq.jpg)

c.

![](https://uofi.box.com/shared/static/zsr6nmyayso7emjkmk6cfwaxs75wujpj.jpg)

5. Using the vector y below
```{r nt5}
set.seed(385)
y <- rnorm(100)
```

  a. Use the which.min and which.max functions to dispay the index corresponding to the minimum and maximum elelments of `y`.
```{r}
which.min(y)
which.max(y)
```
  
  b. Do the which.min and which.max functions work? (try: max(y) == y[which.max(y)]).
```{r}
min(y) == y[which.min(y)]
max(y) == y[which.max(y)]
#yes it works
```
  
  c. Use the which function and the length function to report the proportion of the elements of `y` that are greater than 0.

  d. Discuss why the proportion in **part c** is close to 0.5. Hint: What is the mean of the normal distribution that generated the elements in `y`?
  
  e. Create a factor variable with 50 values of `A` and 50 values of `B`, and name this factor variable `trt`. 
  
  f. Create a data frame consisting of `x` and `trt`.
  